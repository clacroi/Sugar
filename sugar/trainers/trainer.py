"""
Generic module to train a Caffe network and monitor different losses / metrics during training.
"""

import os
from abc import ABC, abstractmethod
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import json

import caffe
from google.protobuf import text_format
from caffe.proto import caffe_pb2
import numpy as np
from datum.feeders import Feeder

from sugar.solvers import Solver
from sugar.evaluators import NetworkEvaluator


class Trainer(ABC):
    """Abstract class to represent a Caffe trainer for training Caffe networks,
    monitoring validation metrics and saving intermediate networks during training.

    Attributes:
        root_dir: root directory for the training.
        _train_net: Caffe training network.
        _train_net_params: Caffe training network layers parameters.
        trainable_weights: list of Caffe layers type to train (others won't be trained)
        train_input_loading_mode: mode for loading inputs into training network.
            'AUTOMATIC' : inputs are loaded automatically by the network first layer.
            'CUSTOM' : inputs are generated by _train_feeder and loaded to net input layers.
        _train_feeder: Datum Feeder object for generating network inputs arrays.
        _evaluators: list of network evaluators to monitor validation metrics during training.
        solver: solver used for training.
        display_interval: network outputs are display every display_interval iterations.
        eval_interval: evaluators outputs are display every eval_interval iterations.
        snapshot_interval: training network weights are saved every snapshot_interval.
        _accumulated_gradients: dict mapping trainable layers names to their accumulated gradients.
    """
    def __init__(self, root_dir: Path,
                 train_net_prototxt: Path, trainable_layers: List[str],
                 train_net_weights: Optional[Path] = None,
                 train_input_loading_mode: Optional[str] = 'CUSTOM',
                 train_feeder: Optional[Feeder] = None,
                 evaluators: Optional[List[NetworkEvaluator]] = None,
                 solver: Optional[Solver] = None,
                 display_interval: Optional[int] = 50,
                 eval_interval: Optional[int] = 500,
                 snapshot_interval: Optional[int] = 2000,
                 caffe_mode: Optional[str] = 'GPU') -> None:
        self.root_dir: Path = root_dir
        if not (self.root_dir / 'snapshots').exists():
            os.makedirs(self.root_dir / 'snapshots')

        # Construct training network
        self.train_net_prototxt: Path = train_net_prototxt
        self.train_net_weights: Optional[Path] = train_net_weights
        self._train_net: caffe.Net = caffe.Net(str(train_net_prototxt), caffe.TRAIN)
        if train_net_weights:
            print('Restoring network weights from {} for training.'.format(train_net_weights))
            self._train_net.copy_from(str(train_net_weights))

        train_net_specs = caffe_pb2.NetParameter()
        with open(train_net_prototxt, "r") as fp:
            text_format.Merge(str(fp.read()), train_net_specs)
        self._train_net_params: Dict[str, Any] = {layer.name: layer for layer in train_net_specs.layer}
        self.trainable_layers: List[str] = trainable_layers
        print('Set of trainable layers : {}'.format(self.trainable_layers))

        # Construct train net input loading mode
        if train_input_loading_mode not in ['AUTOMATIC', 'CUSTOM']:
            raise ValueError('train_input_loading_mode should be in |"AUTOMATIC"|"CUSTOM"|')
        self.train_input_loading_mode: str = train_input_loading_mode
        # TODO : check that train net input layer has correct type in
        # function of train_input_loading_mode ?
        if train_input_loading_mode == 'CUSTOM':
            if not train_feeder:
                raise ValueError('When train input loading type is "CUSTOM",'
                                 'valid train_feeder must be passed.')
        self._train_feeder: Feeder = train_feeder

        # Load evaluators
        self._evaluators: List[NetworkEvaluator] = evaluators if evaluators else []

        self.solver: Solver = solver
        self.display_interval: int = display_interval
        self.eval_interval: int = eval_interval
        self.snapshot_interval: int = snapshot_interval

        if caffe_mode not in ['GPU', 'CPU']:
            raise ValueError('caffe_mode should be in |"GPU"|"CPU"| vs {}'.format(caffe_mode))
        self.caffe_mode: Any = caffe_mode
        if caffe_mode == 'GPU':
            caffe.set_mode_gpu()

        # Save trainer data to json in root_dir
        with open(root_dir / 'trainer.json', 'w') as out_file:
            json.dump(self.to_dict(), out_file, indent=4)

    def to_dict(self) -> Dict[str, Any]:
        """Return a dictionary version json serializable"""
        d = {'trainer_type': type(self).__name__,
             'root_dir': str(self.root_dir),
             'train_net_prototxt': str(self.train_net_prototxt),
             'train_net_weights': str(self.train_net_weights),
             'trainable_layers': self.trainable_layers,
             'train_input_loading_mode': self.train_input_loading_mode,
             'solver': self.solver.to_dict(),
             'display_interval': self.display_interval,
             'eval_interval': self.eval_interval,
             'snapshot_interval': self.snapshot_interval,
             'caffe_mode': str(self.caffe_mode)}
        if self._train_feeder:
            d['train_feeder'] = self._train_feeder.to_dict()
        if self._evaluators:
            d['evaluators'] = [evaluator.to_dict() for evaluator in self._evaluators]
        return d


    def _step(self, it: int, lr: float) -> Dict[str, np.ndarray]:
        """Run 1 training step including forward > backward > weights updates operations.

        Args:
            it: current step number.
            lr: learning rate to use for current step.

        Returns:
            Output of Caffe training net forward pass.
        """
        # before forward > backward > network weights update, reset weights gradients
        self._train_net.clear_param_diffs()

        # Load data batch if necessary
        if self.train_input_loading_mode == 'CUSTOM':
            data_batch = next(self._train_feeder)
            batch_size = data_batch['data'].shape[0]
            for blob_name, blob_data in data_batch.items():
                batch_size = blob_data.shape[0]
                for i in range(batch_size):
                    self._train_net.blobs[blob_name].data[i, ...] = data_batch[blob_name][i, :, :, :]

        # Forward pass
        forward = self._forward()

        # Backward pass
        _ = self._backward()

        # Update network
        self._update_network_weights(it, lr)
        return forward

    def _forward(self) -> Dict[str, np.ndarray]:
        """Run forward pass for training network.

        Returns:
            Output of Caffe training net with current input.
        """
        return self._train_net.forward()

    def _backward(self) -> None:
        """Run backward pass for training network."""
        return self._train_net.backward()

    @abstractmethod
    def _update_network_weights(self, it: int, lr: float) -> None:
        """Update training net with current gradients.

        Args:
            it: current step number.
            lr: learning rate to use for current step.

        Returns:
            Output of Caffe training net forward pass.
        """
        pass

    def _generate_display(self, it: int, lr: float, output: Dict[str, np.ndarray],
                          prefix: Optional[str] = 'Train network') -> str:
        """Generate Caffe-like string to display from network/evaluator output.

        Args:
            it: current step number.
            lr: learning rate to use for current step.
            output: output from training network or training network evaluator.

        Returns:
            String representing output to display during training.
        """
        display = 'Iteration {}/{}, lr = {} :\n'.format(it, self.solver.max_iter, lr)
        k = 0
        for output_name, output_data in output.items():
            if output_data.size > 1:
                for i, output_val in enumerate(output_data):
                    display += '{} output #{}: {}[{}] = {}\n'.format(prefix, k, output_name,
                                                                     i, output_val)
                    k += 1
            else:
                display += '{} output #{}: {} = {}\n'.format(prefix, k, output_name, output_data)
                k += 1
        return display

    def train(self) -> Dict[str, List[Tuple[int, Any]]]:
        """Train the network while monitoring training losses and other training/testing metrics
        and saving network weights periodically.

        Returns:
            Dict mapping training network / evaluators output quantities names to output data.
        """
        train_results = {'lr':[], 'forward_output': {}, 'eval_output': {}}
        # (0) eval network before training
        for evaluator in self._evaluators:
            evaluator.update_from(self._train_net)
            eval_output = evaluator.evaluate()
            display = self._generate_display(0, self.solver.base_lr, eval_output, prefix=evaluator.name)
            with open(self.root_dir / 'training_log', 'a') as training_log:
                training_log.write(display)
            print(display)
            for eval_output_name, eval_output_data in eval_output.items():
                train_results['eval_output'].get(eval_output_name, []).append((0, eval_output_data))

        # (1) start training
        for it in range(self.solver.max_iter + 1):
            lr = self.solver.compute_lr(it)
            train_results['lr'].append((it, lr))
            forward = self._step(it, lr)

            if it > 0 and it % self.display_interval == 0:
                display = self._generate_display(it, lr, forward, prefix='Train network')
                with open(self.root_dir / 'training_log', 'a') as training_log:
                    training_log.write(display)
                print(display)
                for forward_name, forward_data in forward.items():
                    train_results['forward_output'].get(forward_name, []).append((it, forward_data))

            if self._evaluators and it > 0 and it % self.eval_interval == 0:
                for evaluator in self._evaluators:
                    # Update evaluator network and evaluate
                    evaluator.update_from(self._train_net)
                    eval_output = evaluator.evaluate()
                    display = self._generate_display(it, lr, eval_output, prefix=evaluator.name)
                    with open(self.root_dir / 'training_log', 'a') as training_log:
                        training_log.write(display)
                    print(display)
                    for eval_output_name, eval_output_data in eval_output.items():
                        train_results['eval_output'].get(eval_output_name, []).append((it, eval_output_data))

            if it > 0 and it % self.snapshot_interval == 0:
                print('Iteration {}/{} : constructing network snapshot.'.format(it, self.solver.max_iter))
                save_path = '{}/snapshots/_iter_{}.caffemodel'.format(self.root_dir, str(it))
                self._train_net.save(save_path)

        # (2) eval network at end of training and save network
        for evaluator in self._evaluators:
            evaluator.update_from(self._train_net)
            eval_output = evaluator.evaluate()
            display = self._generate_display(it, lr, eval_output, prefix=evaluator.name)
            with open(self.root_dir / 'training_log', 'a') as training_log:
                training_log.write(display)
            print(display)
            for eval_output_name, eval_output_data in eval_output.items():
                train_results['eval_output'].get(eval_output_name, []).append((it, eval_output_data))

        save_path = '{}/snapshots/_iter_{}.caffemodel'.format(self.root_dir, str(it))
        self._train_net.save(save_path)

        return train_results
